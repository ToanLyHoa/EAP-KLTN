{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config.config import get_cfg_defaults\n",
    "from model import generate_model\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "from data_loader import iterator_factory_augmentResNet\n",
    "from loss import create_loss\n",
    "from loss import metric\n",
    "from datetime import datetime\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class Combine(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.backbone = generate_model(cfg.BACKBONE)\n",
    "\n",
    "        # for param in self.backbone.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        # self.head = generate_model(cfg.HEAD)\n",
    "\n",
    "        self.file_name = cfg.TRAIN.MODEL_NAME\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        B, *_ = data.shape\n",
    "\n",
    "        data = rearrange(data, 'b s c t h w -> (b s) c t h w')\n",
    "\n",
    "        # feature: ((b s), c, t, h, w)\n",
    "        # pred: ((b s), n)\n",
    "        features, pred = self.backbone(data)\n",
    "\n",
    "        # features = rearrange(features, '(b s) c t h w -> b s c t h w', b = B)\n",
    "\n",
    "        # features: (b, s, c, t, h, w)\n",
    "        # outputs = self.head(features)\n",
    "        return pred\n",
    "\n",
    "    def save_model(self, file_path, epoch):\n",
    "        file_name = f\"{file_path}-epoch:{epoch}.pth\"\n",
    "        torch.save(self.state_dict(), file_name)\n",
    "        pass\n",
    "\n",
    "    def load_model(self, file_path):\n",
    "        result = torch.load(file_path)\n",
    "        pass\n",
    "\n",
    "def load_checkpoint(cfg ,model):\n",
    "\n",
    "    checkpoint = torch.load(cfg.TRAIN.PRETRAIN_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "\n",
    "    try:\n",
    "        best_acc = checkpoint['best_acc']\n",
    "    except:\n",
    "        best_acc = 0\n",
    "\n",
    "    return epoch, best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg_defaults()\n",
    "config_file = 'log/23_06_13-even_crop_random:1-resnet3d_50--video_per:0.3-video_len16-optimize:SGD-loss:crossentropylossmean/config.yaml'\n",
    "pretrain_path = 'log/23_06_13-even_crop_random:1-resnet3d_50--video_per:0.3-video_len16-optimize:SGD-loss:crossentropylossmean/model_best.pth'\n",
    "\n",
    "cfg.merge_from_file(config_file)\n",
    "\n",
    "# cho pretrain_path\n",
    "cfg.TRAIN.PRETRAIN_PATH = pretrain_path\n",
    "\n",
    "cfg.DATA.EVAL_ONLY = True\n",
    "# đưa batch size về worker về 1 hết\n",
    "cfg.DATA.BATCH_SIZE = 1\n",
    "cfg.DATA.WORKERS = 0\n",
    "cfg.TRAIN.BATCH_SIZE = 1\n",
    "cfg.TRAIN.WORKERS = 0\n",
    "cfg.freeze()\n",
    "\n",
    "\n",
    "model = Combine(cfg).to(cfg.TRAIN.DEVICE)\n",
    "a,b = None, None\n",
    "_, _ = load_checkpoint(cfg, model)\n",
    "\n",
    "import json\n",
    "\n",
    "class_dict = open('label/UCF-101/dictionary.json')\n",
    "class_dict = json.load(class_dict)\n",
    "\n",
    "class_dict_new = {}\n",
    "\n",
    "for key, item in class_dict.items():\n",
    "    class_dict_new[item] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 23:29:03 it-System-Product-Name root[546769] INFO VideoIter:: Found dict at: label/UCF-101/dictionary.json \n",
      "\n",
      "2023-06-20 23:29:03 it-System-Product-Name root[546769] INFO VideoIter:: iterator initialized (phase: 'label/UCF-101/val.csv', num: 3783)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 16, 112, 112])\n",
      "torch.Size([1, 1, 3, 16, 112, 112])\n",
      "torch.Size([1, 1, 3, 16, 112, 112])\n",
      "torch.Size([1, 1, 3, 16, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "val_loader, len_video_val = iterator_factory_augmentResNet.create(cfg.DATA)\n",
    "if cfg.TRAIN.LOSS == 'crossentropylossmean':\n",
    "    criterion = create_loss.CrossEntropyLossMean\n",
    "elif cfg.TRAIN.LOSS == 'crossentropyloss':\n",
    "    criterion = create_loss.CrossEntropyLoss\n",
    "\n",
    "num_test = 2\n",
    "output_test_list = []\n",
    "video_path_test_list = []\n",
    "sampled_indices_list_list = []\n",
    "\n",
    "model.eval()\n",
    "# evaluation\n",
    "with torch.no_grad():\n",
    "\n",
    "    accuracy_val = 0\n",
    "    loss_val = 0\n",
    "\n",
    "    for i, (data, targets, video_path) in enumerate(val_loader):\n",
    "        print(data.shape)\n",
    "        if num_test < 0:\n",
    "            break\n",
    "        num_test -= 1\n",
    "\n",
    "        video_path_test_list.append(video_path)\n",
    "\n",
    "        if i == len(val_loader) - 1:\n",
    "            hihi = 0\n",
    "        data = data.cuda()\n",
    "        targets = targets.cuda()\n",
    "\n",
    "        video = (data[0, 0, ...]*255).detach().cpu().numpy().transpose(1,2,3,0).astype(np.uint8)\n",
    "        xxx = video[0]\n",
    "        # zero the parameter gradients\n",
    "        outputs = model(data)\n",
    "        output_test_list.append(outputs)\n",
    "        outputs = rearrange(outputs, '(b s) c -> b s c', s = cfg.DATA.NUM_SAMPLERS)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # calculate metric here\n",
    "        # val_metric.update(outputs, targets, loss)\n",
    "\n",
    "\n",
    "    # write in file\n",
    "    # val_metric.write_file(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = []\n",
    "\n",
    "for i in range(len(output_test_list)):\n",
    "    _, indices = output_test_list[i].topk(1)\n",
    "\n",
    "    top_k = int(indices)\n",
    "\n",
    "    predict_list.append(class_dict_new[top_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil\n",
    "def delete_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    for filename in os.listdir(folder_name):\n",
    "        file_path = os.path.join(folder_name, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "delete_folder('video_test')\n",
    "\n",
    "import glob   \n",
    "import cv2\n",
    "# đọc video   \n",
    "for i in range(len(video_path_test_list)):\n",
    "    video_path = video_path_test_list[i]\n",
    "    img_list = glob.glob(f'{video_path[0]}/*.jpg')\n",
    "    img_list.sort()\n",
    "\n",
    "    hf, wf, _ = cv2.imread(img_list[0]).shape\n",
    "\n",
    "    result = cv2.VideoWriter(f\"video_test/{video_path[0].split('/')[-1]}.mp4\",\n",
    "                cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "                10, (wf, hf))\n",
    "    \n",
    "    label = video_path[0].split('/')[-2] \n",
    "    predict = predict_list[i]\n",
    "\n",
    "    for img in img_list:\n",
    "        frame = cv2.imread(img)\n",
    "\n",
    "        frame = cv2.putText(frame, f'Label: {label}', (0, 20), cv2.FONT_ITALIC, 0.5, \n",
    "                    (0, 255, 0), 1, cv2.LINE_AA, False)\n",
    "\n",
    "        frame = cv2.putText(frame, f'Predict: {predict}', (0, 60), cv2.FONT_ITALIC, 0.5, \n",
    "                    (0, 0, 255), 1, cv2.LINE_AA, False)\n",
    "\n",
    "        result.write(frame)\n",
    "    print(frame.shape)\n",
    "    \n",
    "    result.release()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TemPr4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
